{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1SV4bEykFES6Pal3XZoE0IvU9AIjw6J6o","timestamp":1698719597560},{"file_id":"1zAI_Eg62DOLNL70xCndEWDRD-G_jV7tX","timestamp":1698718002523},{"file_id":"1uIuNrS0eqjvyRi3ebJTShNS-YmSyP2Lp","timestamp":1698717033477},{"file_id":"1AuoASvRjGs3xlHhLiqTGaIxL8BlA5Q7d","timestamp":1698715712981}],"toc_visible":true,"gpuType":"T4","authorship_tag":"ABX9TyM5B0ct+kaA/bhyOUjPPXBr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Environment\n"],"metadata":{"id":"lTVY4ELxNgF9"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TvaeNqZ_NMwc","executionInfo":{"status":"ok","timestamp":1709649324872,"user_tz":-60,"elapsed":30229,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}},"outputId":"e9a3c315-9f15-4ef6-c972-f129fef287bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.8.0\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Collecting contractions\n","  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n","Collecting textsearch>=0.0.21 (from contractions)\n","  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n","Collecting anyascii (from textsearch>=0.0.21->contractions)\n","  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n","  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n","Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"]}],"source":["from google.colab import drive, runtime\n","import json\n","import string\n","import re\n","import random\n","from collections import defaultdict\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from torch.optim import AdamW\n","!pip install torchinfo\n","from torchinfo import summary\n","\n","\n","import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import WhitespaceTokenizer\n","from nltk.stem.snowball import SnowballStemmer\n","!pip install contractions\n","import contractions\n","\n","seed = 27\n","random.seed(seed)"]},{"cell_type":"code","source":["!python --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uu_AinzvAc4p","executionInfo":{"status":"ok","timestamp":1709649326050,"user_tz":-60,"elapsed":1184,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}},"outputId":"8f3d0cc9-0642-406f-c234-5e617ba174d0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.10.12\n"]}]},{"cell_type":"markdown","source":["# GPU Check"],"metadata":{"id":"1QizZTaBNjsO"}},{"cell_type":"code","source":["# From\n","# https://colab.research.google.com/notebooks/pro.ipynb\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SGcJyjRANlnj","executionInfo":{"status":"ok","timestamp":1709649326050,"user_tz":-60,"elapsed":15,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}},"outputId":"c58a8ca8-4923-4a4f-e951-bcbd4cbad0de"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: nvidia-smi: command not found\n"]}]},{"cell_type":"markdown","source":["# Google Drive"],"metadata":{"id":"ZS2TRPQB6Eyu"}},{"cell_type":"markdown","source":["## Mount Drive"],"metadata":{"id":"PvEjE91bOBmB"}},{"cell_type":"code","source":["## Mount the drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oyTw19EJNl16","executionInfo":{"status":"ok","timestamp":1709649346302,"user_tz":-60,"elapsed":20256,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}},"outputId":"42a66ec0-0903-4bd6-b181-673a996e3312"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Data Paths"],"metadata":{"id":"2PFbLwFFOFBD"}},{"cell_type":"code","source":["# Paths\n","drive_path = \"/content/drive/MyDrive\" # Do not change\n","internal_path = \"Datasets\"\n","file_name = \"ahk_dataset_v2.json\"\n","\n","data_folder = \"/content/data\"\n","!mkdir -p $data_folder\n","!cp $drive_path/$internal_path/$file_name $data_folder/$file_name"],"metadata":{"id":"n2tKaztYOF_s","executionInfo":{"status":"ok","timestamp":1709649347436,"user_tz":-60,"elapsed":1139,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Load Data"],"metadata":{"id":"rl8teBipWY6J"}},{"cell_type":"code","source":["with open(f\"{data_folder}/{file_name}\", 'r') as file:\n","    data = json.load(file)"],"metadata":{"id":"T26kFnnxOiX4","executionInfo":{"status":"ok","timestamp":1709649348184,"user_tz":-60,"elapsed":750,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# Raw Data"],"metadata":{"id":"hIMcwfo95ydT"}},{"cell_type":"markdown","source":["## Statistics"],"metadata":{"id":"LcJvaxjUWn58"}},{"cell_type":"code","source":["help = 0\n","rule_five = 0\n","normal = 0\n","\n","for dp in data:\n","    if dp[\"help\"] == True and dp[\"rule5\"] == False:\n","        help += 1\n","    elif dp[\"rule5\"] == True:\n","        rule_five += 1\n","    else:\n","        normal += 1\n","\n","total = help + rule_five + normal\n","\n","print(f\"There are \\t{help}\\t help samples \\t\\t({(help/total)*100:.2f} %)\")\n","print(f\"\\t\\t{rule_five}\\t rule five samples \\t({(rule_five/total)*100:.2f} %)\")\n","print(f\"\\t\\t{normal}\\t normal samples \\t({(normal/total)*100:.2f} %)\")\n","\n","print(f\"\\nTotal: {total}\")"],"metadata":{"id":"DW3kZagcWnNc","executionInfo":{"status":"ok","timestamp":1709649348765,"user_tz":-60,"elapsed":586,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"247a339c-9ba2-4044-cff8-e09a1977b155"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["There are \t4504\t help samples \t\t(1.86 %)\n","\t\t375\t rule five samples \t(0.15 %)\n","\t\t237416\t normal samples \t(97.99 %)\n","\n","Total: 242295\n"]}]},{"cell_type":"code","source":["print(data[7110][\"text\"])"],"metadata":{"id":"Lg7zRM5ncbQu","executionInfo":{"status":"ok","timestamp":1709649348766,"user_tz":-60,"elapsed":10,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6dda09be-94d6-4293-805d-87d2bd213952"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["walls don't mean shit anymore lmfao but you can also fall through walls so you need to stand \"on top\" of an object or the top of a portal so if you're watching the inbounds speedrun, and they're shooting through walls and shit, they're also juggling where they're standing stand in the wrong spot and they fall through the ground\n"]}]},{"cell_type":"markdown","source":["## Standarize"],"metadata":{"id":"qe0yyeoU09H6"}},{"cell_type":"code","source":["def remove_discord_emojis(text):\n","    emoji_pattern = re.compile(\"[\"\n","                                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","                                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","                                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","                                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","                                u\"\\U00002702-\\U000027B0\"  # other emoticons\n","                                u\"\\U000024C2-\\U0001F251\"  # emojis\n","                                \"]+\", flags=re.UNICODE)\n","\n","    return emoji_pattern.sub(\" \", text)\n","\n","def remove_urls(text):\n","    return re.sub(r\"https?://\\S+\", \" \", text)\n","\n","def remove_mentions(text):\n","    return re.sub(r\"@\\S+\", \"\", text)\n","\n","def remove_custom_emojis(text):\n","    txt = re.sub(r\":\\b(?!\\d\\d)\\w+\\b:\", \" \", text)\n","    return txt\n","\n","def special_to_space(text): # Excludes ' because we need it for contractions\n","    return re.sub(r\"[^a-zA-Z0-9'\\s]+\", \" \", text)\n","\n","def compress_whitespace(text):\n","    return re.sub(r\"\\s+\", \" \", text)\n","\n","\n","def standardize_text(text, stemmer, contractions):\n","    txt = text.lower()\n","\n","    txt = remove_urls(txt)\n","    txt = remove_mentions(txt)\n","    txt = remove_discord_emojis(txt)\n","    txt = remove_custom_emojis(txt)\n","\n","    txt = special_to_space(txt)\n","\n","    words = txt.split()\n","    txt = \"\"\n","    for word in words:\n","        word = contractions.fix(word)\n","        word = re.sub(r\"\\'\", \"\", word)\n","        txt += f\"{word} \" # space for separation\n","\n","    words = txt.split()\n","    txt = \"\"\n","    for word in words:\n","        word = stemmer(word)\n","        txt += f\"{word} \" # space for separation\n","\n","    txt = compress_whitespace(txt)\n","    txt = txt.strip()\n","\n","    return txt"],"metadata":{"id":"fIwiHRUf0-VR","executionInfo":{"status":"ok","timestamp":1709649348766,"user_tz":-60,"elapsed":7,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["stemmer = SnowballStemmer(\"english\")\n","\n","standardizer = lambda x: standardize_text(x, stemmer.stem, contractions)"],"metadata":{"id":"vlwEt63TVVfh","executionInfo":{"status":"ok","timestamp":1709649348766,"user_tz":-60,"elapsed":6,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["print(data[7110][\"text\"])"],"metadata":{"id":"EU207XQhgSrL","executionInfo":{"status":"ok","timestamp":1709649348766,"user_tz":-60,"elapsed":6,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1a733bcc-498f-4209-f337-c57bac09d040"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["walls don't mean shit anymore lmfao but you can also fall through walls so you need to stand \"on top\" of an object or the top of a portal so if you're watching the inbounds speedrun, and they're shooting through walls and shit, they're also juggling where they're standing stand in the wrong spot and they fall through the ground\n"]}]},{"cell_type":"code","source":["for dp in data:\n","    dp[\"text\"] = standardizer(dp[\"text\"])"],"metadata":{"id":"Z9qM8HXecLG4","executionInfo":{"status":"ok","timestamp":1709649414903,"user_tz":-60,"elapsed":66141,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["print(data[7110][\"text\"])"],"metadata":{"id":"yyul09_3sjnU","executionInfo":{"status":"ok","timestamp":1709649414904,"user_tz":-60,"elapsed":8,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0f9efefd-b39f-4aae-a03b-36ac55dcecb5"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["wall do not mean shit anymor lmfao but you can also fall through wall so you need to stand on top of an object or the top of a portal so if you are watch the inbound speedrun and they are shoot through wall and shit they are also juggl where they are stand stand in the wrong spot and they fall through the ground\n"]}]},{"cell_type":"markdown","source":["## Separate Data"],"metadata":{"id":"MMoGdi7r7wyC"}},{"cell_type":"code","source":["texts = []\n","labels = []\n","\n","for dp in data:\n","    texts.append(dp[\"text\"])\n","\n","    help = dp[\"help\"]\n","    rule5 = dp[\"rule5\"]\n","\n","    if rule5 or help:\n","        labels.append([0, int(help), int(rule5)])\n","    else:\n","        labels.append([1, 0, 0])\n"],"metadata":{"id":"5ikSr6nw7wg0","executionInfo":{"status":"ok","timestamp":1709649415701,"user_tz":-60,"elapsed":800,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["print(texts[7110])"],"metadata":{"id":"5tn9_JNbImiI","executionInfo":{"status":"ok","timestamp":1709649415701,"user_tz":-60,"elapsed":9,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1db45e42-216e-4363-e9be-2aee7b16b03a"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["wall do not mean shit anymor lmfao but you can also fall through wall so you need to stand on top of an object or the top of a portal so if you are watch the inbound speedrun and they are shoot through wall and shit they are also juggl where they are stand stand in the wrong spot and they fall through the ground\n"]}]},{"cell_type":"code","source":["print(labels[7110])"],"metadata":{"id":"8DYjfJaXX5bI","executionInfo":{"status":"ok","timestamp":1709649415701,"user_tz":-60,"elapsed":5,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ca2d844a-edfd-441a-dc73-eb527a49ffac"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 0, 0]\n"]}]},{"cell_type":"markdown","source":["# Build Dataset"],"metadata":{"id":"XpkLgCPYr74B"}},{"cell_type":"markdown","source":["## Custom Dataset"],"metadata":{"id":"L_i36mZv6S4M"}},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","    def __init__(self, inputs, labels):\n","        self.inputs = inputs\n","        self.labels = torch.tensor(labels, dtype=torch.float32)\n","\n","    def __len__(self):\n","        return len(self.inputs)\n","\n","    def __getitem__(self, index):\n","        input_data = self.inputs[index]\n","        label = self.labels[index]\n","        return input_data, label"],"metadata":{"id":"gx09JuwRr6nJ","executionInfo":{"status":"ok","timestamp":1709649415701,"user_tz":-60,"elapsed":3,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["ahk_dataset = CustomDataset(texts, labels)"],"metadata":{"id":"Y4uSvxzDsTGD","executionInfo":{"status":"ok","timestamp":1709649416112,"user_tz":-60,"elapsed":413,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["## Random Split"],"metadata":{"id":"3rRwLGnt3i3B"}},{"cell_type":"code","source":["validation_split = 0.1\n","test_split  = 0.1\n","\n","train_split = 1 - validation_split - test_split"],"metadata":{"id":"jHry4uCc3lbp","executionInfo":{"status":"ok","timestamp":1709649416113,"user_tz":-60,"elapsed":13,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["generator = torch.Generator().manual_seed(seed)\n","\n","train_dataset, val_dataset, test_dataset = random_split(\n","    ahk_dataset,\n","    [train_split, validation_split, test_split],\n","    generator=generator\n",")"],"metadata":{"id":"bv5109pY3mmT","executionInfo":{"status":"ok","timestamp":1709649416113,"user_tz":-60,"elapsed":12,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["print(f\"Training: \\t{len(train_dataset)}\")\n","print(f\"Validation: \\t{len(val_dataset)}\")\n","print(f\"Test: \\t\\t{len(test_dataset)}\")"],"metadata":{"id":"r7CP1jjs472F","executionInfo":{"status":"ok","timestamp":1709649416113,"user_tz":-60,"elapsed":12,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0899520e-21b6-4bb0-ff7a-8cc7b0d8735c"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Training: \t193837\n","Validation: \t24229\n","Test: \t\t24229\n"]}]},{"cell_type":"markdown","source":["## Data Loaders"],"metadata":{"id":"X1QX3M866aOL"}},{"cell_type":"code","source":["batch_size = 400"],"metadata":{"id":"CJafRPgK6fLC","executionInfo":{"status":"ok","timestamp":1709649416113,"user_tz":-60,"elapsed":6,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["num_workers = 2\n","prefetch = 2 # batches\n","pin_memory = True # https://pytorch.org/docs/stable/data.html#memory-pinning\n","\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=batch_size,\n","    shuffle=True,\n","    num_workers=num_workers,\n","    prefetch_factor=prefetch,\n","    pin_memory=pin_memory\n",")\n","\n","valid_loader = DataLoader(\n","    val_dataset,\n","    batch_size=batch_size,\n","    shuffle=False,\n","    num_workers=num_workers,\n","    prefetch_factor=prefetch,\n","    pin_memory=pin_memory\n",")\n","\n","test_loader = DataLoader(\n","    test_dataset,\n","    batch_size=batch_size,\n","    shuffle=False,\n","    num_workers=num_workers,\n","    prefetch_factor=prefetch,\n","    pin_memory=pin_memory\n",")"],"metadata":{"id":"VRyrEaVP6cbX","executionInfo":{"status":"ok","timestamp":1709649416113,"user_tz":-60,"elapsed":5,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["# Text Vectorization"],"metadata":{"id":"GlRw2Y8I80v8"}},{"cell_type":"markdown","source":["## Class"],"metadata":{"id":"yi_JNtGXNaWg"}},{"cell_type":"code","source":["class TextVectorization(nn.Module):\n","    def __init__(self, max_vocabulary, max_tokens):\n","        super(TextVectorization, self).__init__()\n","        self.max_tokens = max_tokens\n","        self.max_vocabulary = max_vocabulary\n","        self.word_dictionary = dict()\n","        self.dictionary_size = 0\n","\n","    def adapt(self, dataset):\n","        # Calculate word frequencies\n","        word_frequencies = defaultdict(int)\n","\n","        for text in dataset:\n","            for word in text[0].split():\n","                word_frequencies[word] += 1\n","\n","        # Sort the dictionary by word frequencies in descending order\n","        sorted_word_frequencies = dict(sorted(word_frequencies.items(),\n","                                              key=lambda item: item[1],\n","                                              reverse=True)\n","        )\n","\n","        # Take the top (max_vocabulary - 2) most frequent words\n","        # since indices 0 and 1 are reserved for padding and missing words respectively\n","        most_frequent = list(sorted_word_frequencies.items())[:self.max_vocabulary - 2]\n","        # Note that len(most_frequent) does not necessarily equal\n","        # (max_vocabulary - 2), since there could be less words overall\n","        # than the max_vocabulary limit\n","        self.dictionary_size = len(most_frequent) + 2\n","\n","        # Note starting at 2 since 0 (padding) and 1 (missing) are reserved\n","        for word_value, (word, frequency) in enumerate(most_frequent, 2):\n","            self.word_dictionary[word] = word_value\n","\n","        # if len(self.word_dictionary) < self.max_vocabulary:\n","        #     raise ValueError(\n","        #         f\"Current size of the dictionary ({len(self.word_dictionary)}) \"\n","        #         f\"exceeds the defined limit ({self.max_vocabulary})\"\n","        #     )\n","\n","    def vocabulary_size(self):\n","        return self.dictionary_size\n","\n","    def dictionary(self):\n","        return self.word_dictionary\n","\n","    def forward(self, batch_x):\n","        try:\n","            batch_text_vectors = torch.zeros((len(batch_x), self.max_tokens), dtype=torch.int32)\n","\n","            for i, text in enumerate(batch_x):\n","\n","                # Split the text and tokenize it\n","                words = text.split()[:self.max_tokens]\n","\n","                for pos, word in enumerate(words):\n","                    batch_text_vectors[i, pos] = self.word_dictionary.get(word, 1)\n","\n","            return batch_text_vectors\n","\n","        except IndexError:\n","            print(\"Looks like you are out of indicies\")\n","\n","    # def forward(self, x):\n","    #     text_vector = torch.zeros(self.max_tokens, dtype=torch.int32)\n","\n","    #         # Split the text and tokenize it\n","    #     words = x.split()[:self.max_tokens]\n","\n","    #     for pos, word in enumerate(words):\n","    #         text_vector[pos] = self.word_dictionary.get(word, 1)\n","\n","    #    return text_vector"],"metadata":{"id":"EjK9kvEUnzU4","executionInfo":{"status":"ok","timestamp":1709649416113,"user_tz":-60,"elapsed":4,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["## Adapt"],"metadata":{"id":"G3qRadtONfB2"}},{"cell_type":"code","source":["vectorize_layer = TextVectorization(\n","    max_vocabulary=60000,\n","    max_tokens=150\n",")"],"metadata":{"id":"jvCZamCY1vSZ","executionInfo":{"status":"ok","timestamp":1709649416114,"user_tz":-60,"elapsed":5,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["vectorize_layer.adapt(train_dataset)"],"metadata":{"id":"wyjMmXL2294e","executionInfo":{"status":"ok","timestamp":1709649418585,"user_tz":-60,"elapsed":2476,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["vectorize_layer.vocabulary_size()"],"metadata":{"id":"FF9f6Pmd2-uw","executionInfo":{"status":"ok","timestamp":1709649418586,"user_tz":-60,"elapsed":17,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6616c50a-0d02-4450-d096-a11ca430432b"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["49913"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["# vectorize_layer.dictionary()"],"metadata":{"id":"6TYAZT_8QHNe","executionInfo":{"status":"ok","timestamp":1709649418586,"user_tz":-60,"elapsed":11,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["## Samples Tests"],"metadata":{"id":"1pYHWxZVNgbF"}},{"cell_type":"code","source":["samples = [\n","    \"trvger7 implements the russian style of trap metal perfectly, where he's enjoyable mnogoznaal's music is literally magical triplesixdelete is the best trap metal producer\",\n","    \"That's why I'm going 3090, 24 GB of vram, but the 4070 ti is equal or greater than by 1-5% depending on the title to the 3090 ti so some performance loss but fuck 12 GB of vram utter scam\",\n","    \"ya I always hear about that, have yet to have it happen then again I don't uaually do wild stuff fortnite, I kinda did sketchy stuff, everything else was just keybind stuff\",\n","    \"I went from a full desk as a mouse pad to a giant one, now to one that fits in my laptop bag But I am not a pro gamer so ya\",\n","    \"I've played cs2 yesterday for the first time, and cs overall after like an year or two.  I didn't follow too much info cs2 related, \" +\\\n","    \"I can't say I went in blind but I only knew the most big changes (like smoke).  It's nice, but I wasn't very impressed. That said I don't know what would make me impressed.\" +\\\n","    \"I had some trouble adjusting to the gameplay style. Idk, peeker's advantage feels way bigger than it was before. Also I used to play at 128 tickrate, and shots in the new system \" +\\\n","    \"doesn't seem to be as accurate as they were. Could be my aim being crap after such a long period without playing, but I swear too many eagle shots missed when they were spot on in the model's head.\"\n","]"],"metadata":{"id":"uWXjwc5n42ul","executionInfo":{"status":"ok","timestamp":1709649418586,"user_tz":-60,"elapsed":11,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["for idx, sample in enumerate(samples):\n","    samples[idx] = standardizer(sample)"],"metadata":{"id":"r0-N_VDW5BNP","executionInfo":{"status":"ok","timestamp":1709649418586,"user_tz":-60,"elapsed":10,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["vectorize_layer(samples)"],"metadata":{"id":"niMh0Wsn-LoH","executionInfo":{"status":"ok","timestamp":1709649418586,"user_tz":-60,"elapsed":10,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ae2c963c-6bb4-4526-b2fc-fe11142549b7"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[49911,  1044,     3,  1358,   790,    12,  1841,  1422,   543,   125,\n","            80,     7,   706, 25197,   613,     7,   345,   988, 49912,     7,\n","             3,   245,  1841,  1422,  1977,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [   10,     7,    89,     2,    28,    43,  3565,  1061,  1782,    12,\n","          4078,    17,     3, 10985,  1939,     7,  1580,    35,  3662,   102,\n","            94,    63,   156,   463,    19,     3,   811,     6,     3,  3565,\n","          1939,    26,    57,   752,  2075,    17,   123,   589,  1782,    12,\n","          4078,  4115,  1658,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [  340,     2,   192,   626,    58,    10,    15,   352,     6,    15,\n","             4,   243,    64,   181,     2,    14,     8,     1,    14,  1267,\n","           132,  3416,     2,   155,    12,    52,  2870,   132,   238,   234,\n","            24,    22,  3114,   132,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [    2,   368,    56,     5,   408,  1272,    42,     5,   337,  1486,\n","             6,     5,  1688,    36,    67,     6,    36,    10,   836,    13,\n","            20,   516,  1577,    17,     2,    28,     8,     5,  1029,  1483,\n","            26,   340,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [    2,    15,   104,  2464,   922,    16,     3,   158,    65,    11,\n","          1312,  2065,   168,    21,    50,   128,    35,   228,     2,    52,\n","             8,   587,    88,   112,   703,  2464,   616,     2,    99,    97,\n","             2,   368,    13,  1396,    17,     2,    68,   827,     3,   131,\n","           267,   160,    21,   951,     4,     7,   171,    17,     2,    24,\n","             8,   162,  1423,    10,   186,     2,    14,     8,    47,    31,\n","            39,    51,    37,  1423,     2,    86,    57,  1349,  2237,     6,\n","             3,  1959,   790,     2,    14,     8,    47,     1,  2521,   205,\n","            96,  1124,   102,     4,    24,   169,    87,     2,    32,     6,\n","           104,    45,  3979, 23264,    11,   819,    13,     3,   121,   321,\n","            66,     8,   190,     6,    23,    42,  1730,    42,    30,   141,\n","            92,    23,    20,  1507,    23,  1062,   168,   480,     5,   222,\n","          1713,   251,   104,    17,     2,  1268,    88,   214,  4688,   819,\n","           442,    55,    30,   141,  1173,    19,    13,     3,   933,   473,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n","       dtype=torch.int32)"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["# Transformer"],"metadata":{"id":"sZtXcxiLWNRR"}},{"cell_type":"markdown","source":["## Embeddings"],"metadata":{"id":"xx8fxv1laTXK"}},{"cell_type":"code","source":["class TokenAndPositionEmbedding(nn.Module):\n","    def __init__(self, maxlen, vocab_size, embed_dim):\n","        super(TokenAndPositionEmbedding, self).__init__()\n","\n","        self.token_emb = nn.Embedding(\n","            num_embeddings=vocab_size,\n","            embedding_dim=embed_dim,\n","            padding_idx=0\n","        )\n","\n","        self.pos_emb = nn.Embedding(\n","            num_embeddings=maxlen,\n","            embedding_dim=embed_dim\n","        )\n","\n","    def forward(self, x):\n","        maxlen = x.size(-1)\n","        positions = torch.arange(0, maxlen, dtype=torch.int32, device=x.device)\n","        positions = self.pos_emb(positions)\n","        x = self.token_emb(x)\n","        return x + positions"],"metadata":{"id":"ULa51LB7AX8n","executionInfo":{"status":"ok","timestamp":1709649418587,"user_tz":-60,"elapsed":7,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["### Test"],"metadata":{"id":"haiD7WSqaCRl"}},{"cell_type":"code","source":["random_tokens = torch.randint(\n","    low=0,\n","    high=vectorize_layer.vocabulary_size(),\n","    size=(batch_size, 150),\n","    dtype=torch.int32\n",")\n","\n","test_emb = TokenAndPositionEmbedding(150, vectorize_layer.vocabulary_size(), 16)\n","test_emb_out = test_emb(random_tokens)"],"metadata":{"id":"W9i9wQNLRmML","executionInfo":{"status":"ok","timestamp":1709649418587,"user_tz":-60,"elapsed":6,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["## Transformer Block"],"metadata":{"id":"SJpVVRzdnr3E"}},{"cell_type":"code","source":["class TransformerBlock(nn.Module):\n","    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n","        super().__init__()\n","        self.dropout = nn.Dropout(dropout)\n","        self.attention = nn.MultiheadAttention(\n","            embed_dim,\n","            num_heads,\n","            dropout=dropout,\n","            batch_first=True\n","        )\n","        self.norm_1 = nn.LayerNorm(embed_dim)\n","        self.ffn = nn.Sequential(\n","            nn.Linear(embed_dim, ff_dim),\n","            nn.ReLU(),\n","            nn.Linear(ff_dim, embed_dim)\n","        )\n","        self.norm_2 = nn.LayerNorm(embed_dim)\n","\n","    def forward(self, x):\n","        # Multihead self-attention\n","        attn_output, _ = self.attention(x, x, x)\n","\n","        # Residual connection and normalization\n","        x = x + self.dropout(attn_output)\n","        x = self.norm_1(x)\n","\n","        # Feed-forward network\n","        ffn_output = self.ffn(x)\n","\n","        # Residual connection and normalization\n","        x = x + self.dropout(ffn_output)\n","        x = self.norm_2(x)\n","\n","        return x\n"],"metadata":{"id":"oBxp9XcRWM2j","executionInfo":{"status":"ok","timestamp":1709649418995,"user_tz":-60,"elapsed":414,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":["### Test"],"metadata":{"id":"vUG6bZgdaE1s"}},{"cell_type":"code","source":["test_tblock = TransformerBlock(\n","    embed_dim=16,\n","    num_heads=2,\n","    ff_dim=32,\n","    dropout=0.1\n",")\n","\n","test_tblock_out = test_tblock(test_emb_out)\n","\n","print(test_tblock_out.shape)\n","print(test_tblock_out.dtype)"],"metadata":{"id":"3xFmwf-0SlNx","executionInfo":{"status":"ok","timestamp":1709649419340,"user_tz":-60,"elapsed":347,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2f1ad6d9-95e4-48d5-8be7-42dd8b8a704a"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([400, 150, 16])\n","torch.float32\n"]}]},{"cell_type":"markdown","source":["# Transformer Model"],"metadata":{"id":"XXkKkXvKWcVS"}},{"cell_type":"markdown","source":["## Parameters"],"metadata":{"id":"bAzDwNx2aWyx"}},{"cell_type":"code","source":["max_tokens = 150\n","vocab_size = vectorize_layer.vocabulary_size()\n","embed_dim = 16  # Embedding size for each token\n","num_heads = 2  # Number of attention heads\n","ff_dim = 32  # Hidden layer size in feed forward network inside transformer"],"metadata":{"id":"5mZGurbnZtV0","executionInfo":{"status":"ok","timestamp":1709649419340,"user_tz":-60,"elapsed":5,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["## Artchitecture"],"metadata":{"id":"IWO5Ycj9aYES"}},{"cell_type":"code","source":["class TransformerModel(nn.Module):\n","    def __init__(self, max_tokens, vocab_size, embed_dim, num_heads, ff_dim):\n","        super(TransformerModel, self).__init__()\n","        # self.vectorize_layer = vectorize_layer\n","        self.embedding_layer = TokenAndPositionEmbedding(\n","            max_tokens,\n","            vocab_size,\n","            embed_dim\n","        )\n","        self.transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n","        self.global_avg_pooling = nn.AdaptiveAvgPool1d(1)\n","        self.dropout = nn.Dropout(0.1)\n","        self.fc1 = nn.Linear(embed_dim, 20)\n","        self.fc2 = nn.Linear(20, 3)\n","        self.relu = nn.ReLU()\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, x):\n","        # x = self.vectorize_layer(x)\n","        x = self.embedding_layer(x)\n","        x = self.transformer_block(x)\n","        x = self.global_avg_pooling(x.permute(0, 2, 1)).squeeze(2)\n","        x = self.dropout(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        x = self.softmax(x)\n","        return x"],"metadata":{"id":"wL46x8oQZq84","executionInfo":{"status":"ok","timestamp":1709649419340,"user_tz":-60,"elapsed":4,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":["## Init"],"metadata":{"id":"leYmxgwRaZ0J"}},{"cell_type":"code","source":["model = TransformerModel(\n","    max_tokens=max_tokens,\n","    vocab_size=vocab_size,\n","    embed_dim=embed_dim,\n","    num_heads=num_heads,\n","    ff_dim=ff_dim\n",")"],"metadata":{"id":"JRJMHMWQZoOn","executionInfo":{"status":"ok","timestamp":1709649419341,"user_tz":-60,"elapsed":5,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["## Test"],"metadata":{"id":"v2osSy6pZ7ZT"}},{"cell_type":"code","source":["random_tokens = torch.randint(\n","    low=0,\n","    high=vectorize_layer.vocabulary_size(),\n","    size=(batch_size, 150),\n","    dtype=torch.int32\n",")\n","\n","\n","model.forward(random_tokens)[:5]"],"metadata":{"id":"PI8vnndIZ7J0","executionInfo":{"status":"ok","timestamp":1709649420138,"user_tz":-60,"elapsed":802,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7df5f755-90ef-4d29-a1cc-2ebe5a2fd66a"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.2857, 0.3291, 0.3853],\n","        [0.3191, 0.3226, 0.3583],\n","        [0.2873, 0.3286, 0.3842],\n","        [0.2829, 0.3112, 0.4059],\n","        [0.2910, 0.3431, 0.3659]], grad_fn=<SliceBackward0>)"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","source":["## Summary"],"metadata":{"id":"ceCrFBqgF9Od"}},{"cell_type":"code","source":["random_tokens = torch.randint(\n","    low=0,\n","    high=vectorize_layer.vocabulary_size(),\n","    size=(batch_size, 150),\n","    dtype=torch.int32\n",")\n","\n","summary(model, input_data=random_tokens)"],"metadata":{"id":"vHfEpEW8tbMm","executionInfo":{"status":"ok","timestamp":1709649420624,"user_tz":-60,"elapsed":488,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"59ab5de0-77b1-4aa0-8a53-4d70817b8cb5"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","TransformerModel                         [400, 3]                  --\n","├─TokenAndPositionEmbedding: 1-1         [400, 150, 16]            --\n","│    └─Embedding: 2-1                    [150, 16]                 2,400\n","│    └─Embedding: 2-2                    [400, 150, 16]            798,608\n","├─TransformerBlock: 1-2                  [400, 150, 16]            --\n","│    └─MultiheadAttention: 2-3           [400, 150, 16]            1,088\n","│    └─Dropout: 2-4                      [400, 150, 16]            --\n","│    └─LayerNorm: 2-5                    [400, 150, 16]            32\n","│    └─Sequential: 2-6                   [400, 150, 16]            --\n","│    │    └─Linear: 3-1                  [400, 150, 32]            544\n","│    │    └─ReLU: 3-2                    [400, 150, 32]            --\n","│    │    └─Linear: 3-3                  [400, 150, 16]            528\n","│    └─Dropout: 2-7                      [400, 150, 16]            --\n","│    └─LayerNorm: 2-8                    [400, 150, 16]            32\n","├─AdaptiveAvgPool1d: 1-3                 [400, 16, 1]              --\n","├─Dropout: 1-4                           [400, 16]                 --\n","├─Linear: 1-5                            [400, 20]                 340\n","├─ReLU: 1-6                              [400, 20]                 --\n","├─Dropout: 1-7                           [400, 20]                 --\n","├─Linear: 1-8                            [400, 3]                  63\n","├─Softmax: 1-9                           [400, 3]                  --\n","==========================================================================================\n","Total params: 803,635\n","Trainable params: 803,635\n","Non-trainable params: 0\n","Total mult-adds (M): 320.42\n","==========================================================================================\n","Input size (MB): 0.24\n","Forward/backward pass size (MB): 46.17\n","Params size (MB): 3.21\n","Estimated Total Size (MB): 49.62\n","=========================================================================================="]},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","source":["## Append Pre-processing"],"metadata":{"id":"eQYCGP-rB6jk"}},{"cell_type":"code","source":["class TransformerModel(nn.Module):\n","    def __init__(self, max_tokens, vocab_size, embed_dim, num_heads, ff_dim, vectorize_layer):\n","        super(TransformerModel, self).__init__()\n","        self.vectorize_layer = vectorize_layer\n","        self.embedding_layer = TokenAndPositionEmbedding(\n","            max_tokens,\n","            vocab_size,\n","            embed_dim\n","        )\n","        self.transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n","        self.global_avg_pooling = nn.AdaptiveAvgPool1d(1)\n","        self.dropout = nn.Dropout(0.1)\n","        self.fc1 = nn.Linear(embed_dim, 20)\n","        self.fc2 = nn.Linear(20, 3)\n","        self.relu = nn.ReLU()\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, x):\n","        x = self.vectorize_layer(x)\n","        x = self.embedding_layer(x)\n","        x = self.transformer_block(x)\n","        x = self.global_avg_pooling(x.permute(0, 2, 1)).squeeze(2)\n","        x = self.dropout(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        x = self.softmax(x)\n","        return x"],"metadata":{"id":"NaOc64x2CBB0","executionInfo":{"status":"ok","timestamp":1709649420624,"user_tz":-60,"elapsed":24,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["## Init"],"metadata":{"id":"97IHujOusvkP"}},{"cell_type":"code","source":["model = TransformerModel(\n","    max_tokens=max_tokens,\n","    vocab_size=vocab_size,\n","    embed_dim=embed_dim,\n","    num_heads=num_heads,\n","    ff_dim=ff_dim,\n","    vectorize_layer=vectorize_layer\n",")"],"metadata":{"id":"WqiG_vsFswdd","executionInfo":{"status":"ok","timestamp":1709649420624,"user_tz":-60,"elapsed":24,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":["## Test"],"metadata":{"id":"mkdEGMuHstat"}},{"cell_type":"code","source":["model.forward([\n","        \"This is a test\",\n","        \"trvger7 implement the russian style of trap metal perfect where he is enjoy mnogozna music is liter magic triplesixdelet is the best trap metal produc\"\n","    ]\n",")"],"metadata":{"id":"-YEhM8rostDp","executionInfo":{"status":"ok","timestamp":1709649420624,"user_tz":-60,"elapsed":24,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9dbb3bf2-5780-4f23-b21f-9123da8dadfb"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.3751, 0.3198, 0.3051],\n","        [0.3635, 0.3183, 0.3182]], grad_fn=<SoftmaxBackward0>)"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"GWRoR5Dvv2Jc"}},{"cell_type":"markdown","source":["## Training Pipeline"],"metadata":{"id":"l2PmP_-nfxuP"}},{"cell_type":"code","source":["import torch\n","from tqdm import tqdm\n","\n","class ModelTrainer:\n","    def __init__(self, epochs, loss, optimizer, patience):\n","        self.num_epochs = epochs\n","        self.criterion = loss\n","        self.optimizer = optimizer\n","        self.patience = patience\n","        self.best_validation_loss = float('inf')\n","        self.patience_counter = 0\n","\n","    def calculate_accuracy(self, outputs, labels, threshold=0.5):\n","        # Convert outputs to binary predictions\n","        preds = outputs > threshold\n","        # Calculate accuracy\n","        accuracy = (preds == labels.byte()).float().mean()\n","        return accuracy.item()\n","\n","    def train(self, model, train_loader, valid_loader):\n","        for epoch in range(self.num_epochs):\n","            model.train()\n","            total_loss = 0.0\n","            total_accuracy = 0.0\n","\n","            train_progress = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}/{self.num_epochs}\")\n","\n","            for batch_idx, batch in train_progress:\n","                inputs, labels = batch[0], batch[1]\n","\n","                # Forward pass\n","                outputs = model(inputs)\n","                loss = self.criterion(outputs, labels)\n","\n","                # Backward pass and optimization\n","                self.optimizer.zero_grad()\n","                loss.backward()\n","                self.optimizer.step()\n","\n","                total_loss += loss.item()\n","                accuracy = self.calculate_accuracy(outputs, labels)\n","                total_accuracy += accuracy\n","                train_progress.set_postfix(train_loss=total_loss / (batch_idx + 1), train_accuracy=total_accuracy / (batch_idx + 1))\n","\n","            # Evaluate the model on the validation dataset\n","            model.eval()\n","            validation_loss = 0.0\n","            validation_accuracy = 0.0\n","\n","            valid_progress = tqdm(enumerate(valid_loader), total=len(valid_loader), desc=f\"Epoch {epoch + 1}/{self.num_epochs}\")\n","\n","            for batch_idx, batch in valid_progress:\n","                inputs, labels = batch[0], batch[1]\n","                outputs = model(inputs)\n","                loss = self.criterion(outputs, labels)\n","                validation_loss += loss.item()\n","                accuracy = self.calculate_accuracy(outputs, labels)\n","                validation_accuracy += accuracy\n","                valid_progress.set_postfix(validation_loss=validation_loss / (batch_idx + 1), validation_accuracy=validation_accuracy / (batch_idx + 1))\n","\n","            # Check for early stopping\n","            if validation_loss < self.best_validation_loss:\n","                self.best_validation_loss = validation_loss\n","                self.patience_counter = 0\n","            else:\n","                self.patience_counter += 1\n","\n","            if self.patience_counter >= self.patience:\n","                print(f\"Early stopping after {self.patience} epochs without improvement.\")\n","                break\n","\n","            print(\"\\n\")\n","\n","        if self.patience_counter < self.patience:\n","            print(\"Training completed within patience. No early stopping applied.\")\n","\n"],"metadata":{"id":"Vwy3ooWue23a","executionInfo":{"status":"ok","timestamp":1709649420624,"user_tz":-60,"elapsed":20,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"6URUPnlLf0HJ"}},{"cell_type":"code","source":["learning_rate = 0.00003\n","weight_decay = 0.001\n","patience = 8\n","epochs = 50\n","\n","pos_weights = torch.tensor([0, 50, 500])\n","loss = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n","# loss = nn.BCELoss()\n","\n","optimizer = AdamW(\n","    model.parameters(),\n","    lr=learning_rate,\n","    weight_decay=weight_decay\n",")\n","\n","model_trainer = ModelTrainer(\n","    epochs=epochs,\n","    loss=loss,\n","    optimizer=optimizer,\n","    patience=patience\n",")\n","\n","model_trainer.train(\n","    model=model,\n","    train_loader=train_loader,\n","    valid_loader=valid_loader\n",")"],"metadata":{"id":"0igvh6h7v3h1","executionInfo":{"status":"error","timestamp":1709659818761,"user_tz":-60,"elapsed":10370558,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"18198eef-de0f-4496-d2dc-4b1561b1f1bd"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/50: 100%|██████████| 485/485 [06:55<00:00,  1.17it/s, train_accuracy=0.666, train_loss=0.896]\n","Epoch 1/50: 100%|██████████| 61/61 [00:20<00:00,  3.04it/s, validation_accuracy=0.666, validation_loss=0.906]"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 2/50: 100%|██████████| 485/485 [06:53<00:00,  1.17it/s, train_accuracy=0.751, train_loss=0.891]\n","Epoch 2/50: 100%|██████████| 61/61 [00:20<00:00,  3.01it/s, validation_accuracy=0.986, validation_loss=0.901]"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 3/50: 100%|██████████| 485/485 [06:56<00:00,  1.16it/s, train_accuracy=0.958, train_loss=0.884]\n","Epoch 3/50: 100%|██████████| 61/61 [00:21<00:00,  2.81it/s, validation_accuracy=0.986, validation_loss=0.896]"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 4/50: 100%|██████████| 485/485 [06:53<00:00,  1.17it/s, train_accuracy=0.984, train_loss=0.88]\n","Epoch 4/50: 100%|██████████| 61/61 [00:21<00:00,  2.83it/s, validation_accuracy=0.986, validation_loss=0.892]"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 5/50: 100%|██████████| 485/485 [06:52<00:00,  1.18it/s, train_accuracy=0.986, train_loss=0.876]\n","Epoch 5/50: 100%|██████████| 61/61 [00:19<00:00,  3.05it/s, validation_accuracy=0.986, validation_loss=0.89]"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 6/50: 100%|██████████| 485/485 [06:56<00:00,  1.16it/s, train_accuracy=0.986, train_loss=0.874]\n","Epoch 6/50: 100%|██████████| 61/61 [00:21<00:00,  2.89it/s, validation_accuracy=0.986, validation_loss=0.888]"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 7/50: 100%|██████████| 485/485 [07:02<00:00,  1.15it/s, train_accuracy=0.986, train_loss=0.872]\n","Epoch 7/50: 100%|██████████| 61/61 [00:20<00:00,  3.01it/s, validation_accuracy=0.986, validation_loss=0.886]"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 8/50: 100%|██████████| 485/485 [06:59<00:00,  1.15it/s, train_accuracy=0.986, train_loss=0.869]\n","Epoch 8/50: 100%|██████████| 61/61 [00:35<00:00,  1.70it/s, validation_accuracy=0.986, validation_loss=0.882]"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 9/50: 100%|██████████| 485/485 [07:05<00:00,  1.14it/s, train_accuracy=0.986, train_loss=0.865]\n","Epoch 9/50: 100%|██████████| 61/61 [00:21<00:00,  2.79it/s, validation_accuracy=0.986, validation_loss=0.877]"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 10/50: 100%|██████████| 485/485 [07:22<00:00,  1.10it/s, train_accuracy=0.986, train_loss=0.861]\n","Epoch 10/50: 100%|██████████| 61/61 [00:21<00:00,  2.77it/s, validation_accuracy=0.986, validation_loss=0.87]"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 11/50: 100%|██████████| 485/485 [07:15<00:00,  1.11it/s, train_accuracy=0.986, train_loss=0.854]\n","Epoch 11/50: 100%|██████████| 61/61 [00:20<00:00,  2.95it/s, validation_accuracy=0.986, validation_loss=0.861]"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 12/50: 100%|██████████| 485/485 [07:03<00:00,  1.14it/s, train_accuracy=0.985, train_loss=0.847]\n","Epoch 12/50: 100%|██████████| 61/61 [00:21<00:00,  2.80it/s, validation_accuracy=0.985, validation_loss=0.853]"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 13/50: 100%|██████████| 485/485 [07:16<00:00,  1.11it/s, train_accuracy=0.984, train_loss=0.839]\n","Epoch 13/50: 100%|██████████| 61/61 [00:21<00:00,  2.84it/s, validation_accuracy=0.983, validation_loss=0.845]"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 14/50: 100%|██████████| 485/485 [07:08<00:00,  1.13it/s, train_accuracy=0.981, train_loss=0.831]\n","Epoch 14/50: 100%|██████████| 61/61 [00:22<00:00,  2.69it/s, validation_accuracy=0.98, validation_loss=0.838]"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 15/50: 100%|██████████| 485/485 [07:11<00:00,  1.12it/s, train_accuracy=0.978, train_loss=0.824]\n","Epoch 15/50: 100%|██████████| 61/61 [00:21<00:00,  2.86it/s, validation_accuracy=0.976, validation_loss=0.831]"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 16/50: 100%|██████████| 485/485 [07:11<00:00,  1.12it/s, train_accuracy=0.974, train_loss=0.818]\n","Epoch 16/50: 100%|██████████| 61/61 [00:20<00:00,  2.91it/s, validation_accuracy=0.975, validation_loss=0.826]"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 17/50: 100%|██████████| 485/485 [07:06<00:00,  1.14it/s, train_accuracy=0.97, train_loss=0.813]\n","Epoch 17/50: 100%|██████████| 61/61 [00:20<00:00,  2.91it/s, validation_accuracy=0.968, validation_loss=0.821]"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 18/50: 100%|██████████| 485/485 [06:54<00:00,  1.17it/s, train_accuracy=0.964, train_loss=0.808]\n","Epoch 18/50: 100%|██████████| 61/61 [00:22<00:00,  2.70it/s, validation_accuracy=0.963, validation_loss=0.818]"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 19/50: 100%|██████████| 485/485 [06:58<00:00,  1.16it/s, train_accuracy=0.959, train_loss=0.804]\n","Epoch 19/50: 100%|██████████| 61/61 [00:20<00:00,  2.94it/s, validation_accuracy=0.96, validation_loss=0.814]"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 20/50: 100%|██████████| 485/485 [07:04<00:00,  1.14it/s, train_accuracy=0.957, train_loss=0.8]\n","Epoch 20/50: 100%|██████████| 61/61 [00:20<00:00,  2.96it/s, validation_accuracy=0.952, validation_loss=0.811]"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 21/50: 100%|██████████| 485/485 [07:04<00:00,  1.14it/s, train_accuracy=0.952, train_loss=0.797]\n","Epoch 21/50: 100%|██████████| 61/61 [00:20<00:00,  2.97it/s, validation_accuracy=0.948, validation_loss=0.809]"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 22/50: 100%|██████████| 485/485 [07:06<00:00,  1.14it/s, train_accuracy=0.95, train_loss=0.795]\n","Epoch 22/50: 100%|██████████| 61/61 [00:21<00:00,  2.89it/s, validation_accuracy=0.948, validation_loss=0.807]"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 23/50: 100%|██████████| 485/485 [07:04<00:00,  1.14it/s, train_accuracy=0.949, train_loss=0.793]\n","Epoch 23/50: 100%|██████████| 61/61 [00:21<00:00,  2.88it/s, validation_accuracy=0.946, validation_loss=0.805]"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Epoch 24/50:  27%|██▋       | 132/485 [01:56<05:11,  1.13it/s, train_accuracy=0.945, train_loss=0.8]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-3d26b0ae88e4>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m model_trainer.train(\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-44-f0c6eaa13c99>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, train_loader, valid_loader)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-41-036afee1dc6e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_avg_pooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-34-4016e2d2198b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Multihead self-attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Residual connection and normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                 is_causal=is_causal)\n\u001b[1;32m   1240\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1242\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5406\u001b[0m         \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdropout_p\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5408\u001b[0;31m             \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5410\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[0;31m# Activation functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1250\u001b[0m     r\"\"\"\n\u001b[1;32m   1251\u001b[0m     \u001b[0mDuring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomly\u001b[0m \u001b[0mzeroes\u001b[0m \u001b[0msome\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0melements\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["sample = \"Can someone help with an ahk script?\"\n","std_sample = standardizer(sample)\n","print(std_sample)\n","\n","model([std_sample])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wkqBi5wUqtr3","executionInfo":{"status":"ok","timestamp":1709660213306,"user_tz":-60,"elapsed":282,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}},"outputId":"0c0991f4-4a8c-462b-b240-97e5088a5efd"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["can someon help with an ahk script\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[0.8151, 0.1315, 0.0534]], grad_fn=<SoftmaxBackward0>)"]},"metadata":{},"execution_count":53}]},{"cell_type":"markdown","source":["# Unassign"],"metadata":{"id":"bJ_u7HDkL8mB"}},{"cell_type":"code","source":["# runtime.unassign()"],"metadata":{"id":"7UDOoh6EL3ee","executionInfo":{"status":"aborted","timestamp":1709659818762,"user_tz":-60,"elapsed":5,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CoQV-NsS7bid","executionInfo":{"status":"aborted","timestamp":1709659818763,"user_tz":-60,"elapsed":5,"user":{"displayName":"jaroslaw janas","userId":"03851081589721476818"}}},"execution_count":null,"outputs":[]}]}